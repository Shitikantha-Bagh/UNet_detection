{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mTF_ENABLE_TENSORRT\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m(Conv2D,MaxPool2D,Conv2DTranspose,concatenate,Dropout,Input,Lambda)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_TENSORRT']='1'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import(Conv2D,MaxPool2D,Conv2DTranspose,concatenate,Dropout,Input,Lambda)\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "print(\"cuDNN version\",tf.config.list_physical_devices('GPU')[0].properties['cudnn_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_gen_args={\n",
    "    'rescale':1.0/255,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Create ImageDataGenerator instances for images and masks\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Define the image and mask generators using flow_from_directory\n",
    "batch_size = 2\n",
    "\n",
    "# Use the same seed for image and mask generators to ensure they apply the same transformations\n",
    "seed = 42\n",
    "\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/train_images/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    shuffle=False\n",
    "    \n",
    ")\n",
    "\n",
    "train_mask_generator = mask_datagen.flow_from_directory(\n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/train_masks/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_image_generator = image_datagen.flow_from_directory(\n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/val_images/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_mask_generator = mask_datagen.flow_from_directory(\n",
    "    \n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/val_masks/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_image_generator = image_datagen.flow_from_directory(\n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/test_images/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_mask_generator = mask_datagen.flow_from_directory(\n",
    "    '/home/carl/Downloads/detection/datasets/trainset_081023/test_masks/',\n",
    "    target_size = (256,256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Combine image and mask generators using zip\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the outputs of data generators are correct\n",
    "\n",
    "x= train_image_generator.next()\n",
    "y=train_mask_generator.next()\n",
    "for i in range(0,1):\n",
    "    image = x[i]\n",
    "    mask=y[i]\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[:,:,0],cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask[:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape):\n",
    "   \n",
    "    inputs = Input(shape=input_shape)\n",
    "    s = Lambda(lambda x: x/255)(inputs)\n",
    "\n",
    "    #Encoder\n",
    "    conv0 =Conv2D(16,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding='same')(s)\n",
    "    conv0 = Dropout(0.1)(conv0)\n",
    "    conv0 =Conv2D(16,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding='same')(conv0)\n",
    "    pool0= MaxPool2D(pool_size=(2,2))(conv0)\n",
    "\n",
    "\n",
    "    conv1=Conv2D(32,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(pool0)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    conv1=Conv2D(32,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(conv1)\n",
    "    pool1= MaxPool2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "\n",
    "    conv2=Conv2D(64,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(pool1)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    conv2=Conv2D(64,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(conv2)\n",
    "    pool2= MaxPool2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "\n",
    "    conv3=Conv2D(128,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(pool2)\n",
    "    conv3 = Dropout(0.1)(conv3)\n",
    "    conv3=Conv2D(128,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(conv3)\n",
    "    pool3=MaxPool2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "\n",
    "    conv4 =Conv2D(256,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(pool3)\n",
    "    conv4 = Dropout(0.1)(conv4)\n",
    "    conv4=Conv2D(256,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\", padding=\"same\")(conv4)\n",
    "    pool4=MaxPool2D(pool_size=(2,2))(conv4)\n",
    "    \n",
    "\n",
    "    #Middle\n",
    "\n",
    "    convm=Conv2D(512,3,activation=\"relu\",padding=\"same\")(pool4)\n",
    "    convm=Conv2D(512,3,activation=\"relu\",padding=\"same\")(convm)\n",
    "    \n",
    "    #Decoder\n",
    "\n",
    "    deconv4=Conv2DTranspose(256,(2,2),strides=(2,2),padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4,conv4],axis=3)\n",
    "      \n",
    "    uconv4=Conv2D(256,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv4)\n",
    "    uconv4 = Dropout(0.1)(uconv4)\n",
    "    uconv4=Conv2D(256,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv4)\n",
    "    \n",
    "\n",
    "   \n",
    "    deconv3=Conv2DTranspose(128,(2,2),strides=(2,2),padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3,conv3],axis=3)\n",
    "    \n",
    "    \n",
    "    uconv3=Conv2D(128,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv3)\n",
    "    uconv3 = Dropout(0.1)(uconv3)\n",
    "    uconv3=Conv2D(128,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv3)\n",
    "\n",
    "\n",
    "    deconv2=Conv2DTranspose(64,3,strides=(2,2),padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2,conv2],axis=3)\n",
    "    \n",
    "    \n",
    "    uconv2=Conv2D(64,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv2)\n",
    "    uconv2 = Dropout(0.1)(uconv2)\n",
    "    uconv2=Conv2D(64,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1=Conv2DTranspose(64,3,strides=(2,2),padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1,conv1],axis=3)\n",
    "    \n",
    "    \n",
    "    uconv1=Conv2D(32,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv1)\n",
    "    uconv1 = Dropout(0.1)(uconv1)\n",
    "    uconv1=Conv2D(32,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv1)\n",
    "\n",
    "    deconv0=Conv2DTranspose(64,3,strides=(2,2),padding=\"same\")(uconv1)\n",
    "    uconv0 = concatenate([deconv0,conv0],axis=3)\n",
    "    \n",
    "    \n",
    "    uconv0=Conv2D(16,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv0)\n",
    "    uconv0 = Dropout(0.1)(uconv0)\n",
    "    uconv0=Conv2D(16,(3,3),activation=\"relu\",kernel_initializer =\"he_normal\",padding=\"same\")(uconv0)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #output\n",
    "\n",
    "    output_layer = (Conv2D(1,(1,1),activation=\"sigmoid\"))(uconv0)\n",
    "    model = Model(inputs=inputs,outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    \n",
    "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
    "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
    "    gradient.\n",
    "    \n",
    "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "    \n",
    "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "    @author: wassname\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "#Dice metric\n",
    "\n",
    "def dice_metric(y_pred,y_true):\n",
    "    intersection = K.sum(K.sum(K.abs(y_true*y_pred),axis=-1))\n",
    "    union = K.sum(K.sum(K.abs(y_true)+K.abs(y_pred),axis=-1))\n",
    "\n",
    "    return 2*intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256,256,3)\n",
    "model = unet_model(input_shape)\n",
    "model.compile(optimizer='adam',loss=[jaccard_distance_loss],metrics=['accuracy',dice_metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model checkpoint\n",
    "\n",
    "checkpointer=tf.keras.callbacks.ModelCheckpoint('joint_model.h5',verbose=1,save_best_only=True)\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4,monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "\n",
    "num_train_imgs = len(os.listdir('/home/carl/Downloads/detection/datasets/trainset_081023/train_images/train/'))\n",
    "steps_per_epoch = num_train_imgs//batch_size\n",
    "\n",
    "\n",
    "history = model.fit(train_generator,steps_per_epoch=steps_per_epoch,epochs=50,validation_data=val_generator,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "#acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "#val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
